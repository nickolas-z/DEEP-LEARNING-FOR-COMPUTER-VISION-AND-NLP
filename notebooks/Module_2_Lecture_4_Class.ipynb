{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4df0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel '.venv (Python 3.12.3)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. WebSocket is not defined"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import TargetEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import root_mean_squared_error as RMSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f5b5f",
   "metadata": {},
   "source": [
    "# Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70ad17b",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4b597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Module_2_Lecture_2_Class_penguins.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ceae4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9effef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0386d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "ax = sns.countplot(data=df, x='species')\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i)\n",
    "    ax.set_xlabel(\"value\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "            \n",
    "plt.suptitle(\"Target feature distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8948cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "ax = sns.countplot(data=df, x='island')\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i)\n",
    "    ax.set_xlabel(\"value\")\n",
    "    ax.set_ylabel(\"count\")\n",
    "            \n",
    "plt.suptitle(\"Island feature distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b682cfd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "sns.pairplot(data=df, hue='species').fig.suptitle('Numeric features distribution', y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f0029a",
   "metadata": {},
   "source": [
    "## Feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04338598",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['species', 'bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b008b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa2315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['species']=='Adelie', 'species']=0\n",
    "df.loc[df['species']=='Gentoo', 'species']=1\n",
    "df.loc[df['species']=='Chinstrap', 'species']=2\n",
    "df = df.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25674fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "\n",
    "X = df.drop('species', axis =1).values\n",
    "y = df['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f2a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b34954",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31efe2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X, y, random_state = 42, test_size =0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccbb191",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af6e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.Tensor(X_train).float()\n",
    "y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "X_test = torch.Tensor(X_test).float()\n",
    "y_test = torch.Tensor(y_test).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ea1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train[:1])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f59ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim=20, out_dim=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = torch.nn.Sequential(\n",
    "            \n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(hidden_dim, out_dim),\n",
    "            nn.Softmax()\n",
    "        )    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.features(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85675892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearModel(X_train.shape[1], 20, 3)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epoch = 400 \n",
    "\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    # train the model\n",
    "    model.train()\n",
    "    \n",
    "    outputs = model(X_train)\n",
    "    \n",
    "    loss = criterion(outputs, y_train)    \n",
    "    train_loss.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    optimizer.zero_grad()    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    acc = 100 * torch.sum(y_train==torch.max(outputs.data, 1)[1]).double() / len(y_train)\n",
    "    train_accs.append(acc)\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print ('Epoch [%d/%d] Loss: %.4f   Acc: %.4f' \n",
    "                       %(epoch+1, num_epoch, loss.item(), acc.item()))\n",
    "        \n",
    "    # test the model\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        \n",
    "        loss = criterion(outputs, y_test)\n",
    "        test_loss.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "        acc = 100 * torch.sum(y_test==torch.max(outputs.data, 1)[1]).double() / len(y_test)\n",
    "        test_accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823b537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(train_loss, label='Train')\n",
    "plt.plot(test_loss, label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-Entropy Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27126c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(train_accs, label='Train')\n",
    "plt.plot(test_accs, label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Validation Metric')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b0bf9",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5279f810",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034fa6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/Module_2_Lecture_2_Class_bigmart_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820351a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreating preprocessing from the ML course\n",
    "\n",
    "data['Outlet_Establishment_Year'] = 2013 - data['Outlet_Establishment_Year']\n",
    "data['Item_Visibility'] = (data['Item_Visibility']\n",
    "                           .mask(data['Item_Visibility'].eq(0), np.nan))\n",
    "\n",
    "data['Item_Visibility_Avg'] = (data\n",
    "                               .groupby(['Item_Type',\n",
    "                                         'Outlet_Type'])['Item_Visibility']\n",
    "                               .transform('mean'))\n",
    "\n",
    "data['Item_Visibility'] = (\n",
    "    data['Item_Visibility'].fillna(data['Item_Visibility_Avg']))\n",
    "\n",
    "data['Item_Visibility_Ratio'] = (\n",
    "    data['Item_Visibility'] / data['Item_Visibility_Avg'])\n",
    "\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({\n",
    "    'low fat': 'Low Fat',\n",
    "    'LF': 'Low Fat',\n",
    "    'reg': 'Regular'})\n",
    "\n",
    "data['Item_Identifier_Type'] = data['Item_Identifier'].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.select_dtypes(include=np.number)\n",
    "data_cat = data.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "\n",
    "X_train_num, X_test_num, X_train_cat,  X_test_cat, y_train, y_test = (\n",
    "    train_test_split(\n",
    "        data_num.drop(['Item_Outlet_Sales',\n",
    "                       'Item_Visibility_Avg'], axis=1).values,\n",
    "        data_cat.drop('Item_Identifier', axis=1).values,\n",
    "        data['Item_Outlet_Sales'].values,\n",
    "        test_size=0.2,\n",
    "        random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf1f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imputer = SimpleImputer().set_output(transform='pandas')\n",
    "\n",
    "X_train_num = num_imputer.fit_transform(X_train_num)\n",
    "X_test_num = num_imputer.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_imputer = SimpleImputer(\n",
    "    strategy='most_frequent').set_output(transform='pandas')\n",
    "\n",
    "X_train_cat = cat_imputer.fit_transform(X_train_cat)\n",
    "X_test_cat = cat_imputer.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_auto = TargetEncoder(random_state=42).set_output(transform='pandas')\n",
    "\n",
    "X_train_cat = enc_auto.fit_transform(X_train_cat, y_train)\n",
    "X_test_cat = enc_auto.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc1c3c",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1dd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a PyTorch Dataset\n",
    "\n",
    "class BigmartDataset(Dataset):\n",
    "    def __init__(self, X, y, scale=True):        \n",
    "        self.X = X.values # from Pandas DataFrame to NumPy array\n",
    "        self.y = y\n",
    "        \n",
    "        if scale:\n",
    "            sc = StandardScaler()\n",
    "            self.X = sc.fit_transform(self.X)\n",
    "\n",
    "    def __len__(self):\n",
    "        #return size of a dataset\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #supports indexing using dataset[i] to get the i-th row in a dataset\n",
    "        \n",
    "        X = torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(self.y[idx], dtype=torch.float32)        \n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c3e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating train and test datasets\n",
    "\n",
    "train_dataset = BigmartDataset(X_train, y_train)\n",
    "test_dataset = BigmartDataset(X_test, y_test)\n",
    "\n",
    "# Loading Batches of Data\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=200,\n",
    "                              num_workers=4\n",
    "                             )\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                              batch_size=200,\n",
    "                              num_workers=4\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ec975c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7174da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = torch.nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            torch.nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64, out_dim),\n",
    "        )\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.features(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95797e",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LinearModel(in_dim=X_train.shape[1], out_dim=1)\n",
    "  \n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "train_losses = []\n",
    "train_rmses = []\n",
    "test_losses = []\n",
    "test_rmses = []\n",
    "\n",
    "# Train the model\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Train step\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    y_pred_train = []\n",
    "    \n",
    "    for data in train_dataloader:\n",
    "        # Get and prepare inputs\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.float(), targets.float()\n",
    "        targets = targets.reshape((targets.shape[0], 1))\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred_train.extend(outputs.cpu().detach().numpy())\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, RMSE: {RMSE(y_train, y_pred_train)}')\n",
    "    train_rmses.append(RMSE(y_train, y_pred_train))\n",
    "    train_losses.append(loss.cpu().detach().numpy())\n",
    "    \n",
    "    # Eval step\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    y_pred_test = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data in test_dataloader:\n",
    "            # Get and prepare inputs\n",
    "            inputs, targets = data\n",
    "            inputs, targets = inputs.float(), targets.float()\n",
    "            targets = targets.reshape((targets.shape[0], 1))\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # No backward pass\n",
    "            \n",
    "            y_pred_test.extend(outputs.cpu().detach().numpy())\n",
    "        \n",
    "        test_rmses.append(RMSE(y_test, y_pred_test))\n",
    "        test_losses.append(loss.cpu().detach().numpy())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2237c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(train_losses, label='Train')\n",
    "plt.plot(test_losses, label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "plt.plot(train_rmses, label='Train')\n",
    "plt.plot(test_rmses, label='Validation')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training vs Validation Metric - RMSE')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
